<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1" /> <title>Solvepnp 5 Methods In Opencv3 · Nimo's Blog</title> <meta name="description" content="Before BeginSolvePnP , Finds an object pose from 3D-2D point correspondences., which is the method that rebuild 3D position from 2D picture."> <link rel="icon" href="https://nimohunter.com/assets/favicon.png"> <link rel="apple-touch-icon" href="https://nimohunter.com/assets/touch-icon.png"> <link rel="stylesheet" href="https://nimohunter.com/assets/core.css"> <link rel="canonical" href="https://nimohunter.com/SolvePnP-5-Methods-in-Opencv3"> <link rel="alternate" type="application/atom+xml" title="Nimo's Blog" href="https://nimohunter.com/feed.xml" /> <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> </head> <body> <aside class="logo"> <a href="https://nimohunter.com/"> <img src="https://avatars2.githubusercontent.com/u/5528309?v=4" alt="" class="logo-avatar"> </a> <span class="logo-prompt code">Back to Index</span> </aside> <div id="content"> <article> <div class="center"> <h1 class="title">Solvepnp 5 Methods In Opencv3</h1> <time class="code">March 21, 2017</time> </div> <div class="divider"></div> <h4 id="before-begin">Before Begin</h4> <p>SolvePnP , Finds an object pose from 3D-2D point correspondences., which is the method that rebuild 3D position from 2D picture.</p> <p>We DO NOT Care about the how to use SolvePnP, we try to understand the inner meaning of SolvePnP, and the 5 methods.</p> <h4 id="solvepnp-methods-and-paper-table">SolvePnP Methods and Paper table:</h4> <table> <thead> <tr> <th style="text-align: center">SolvePnP Methods</th> <th style="text-align: center">Reference Paper</th> <th style="text-align: center">year</th> <th style="text-align: center"> </th> </tr> </thead> <tbody> <tr> <td style="text-align: center">SOLVEPNP_ITERATIVE</td> <td style="text-align: center">Original based on Levenberg-Marquardt optimization</td> <td style="text-align: center"> </td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: center">SOLVEPNP_EPNP</td> <td style="text-align: center">EPnP: Efficient Perspective-n-Point Camera Pose Estimation</td> <td style="text-align: center">2008</td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: center">SOLVEPNP_P3P</td> <td style="text-align: center">Complete Solution Classification for the Perspective-Three-Point Problem</td> <td style="text-align: center">2003</td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: center">SOLVEPNP_DLS</td> <td style="text-align: center">A Direct Least-Squares (DLS) Method for PnP</td> <td style="text-align: center">2011</td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: center">SOLVEPNP_UPNP</td> <td style="text-align: center">Exhaustive Linearization for Robust Camera Pose and Focal Length Estimation</td> <td style="text-align: center">2013</td> <td style="text-align: center"> </td> </tr> </tbody> </table> <p>Methods for solving a PnP problem:</p> <ul> <li><strong>SOLVEPNP_ITERATIVE</strong> Iterative method is based on Levenberg-Marquardt optimization. In this case the function finds such a pose that minimizes reprojection error, that is the sum of squared distances between the observed projections imagePoints and the projected (using projectPoints ) objectPoints .</li> <li><strong>SOLVEPNP_P3P</strong> Method is based on the paper of X.S. Gao, X.-R. Hou, J. Tang, H.-F. Chang “Complete Solution Classification for the Perspective-Three-Point Problem”. In this case the function requires exactly four object and image points.</li> <li><strong>SOLVEPNP_EPNP</strong> Method has been introduced by F.Moreno-Noguer, V.Lepetit and P.Fua in the paper “EPnP: Efficient Perspective-n-Point Camera Pose Estimation”.</li> <li><strong>SOLVEPNP_DLS</strong> Method is based on the paper of Joel A. Hesch and Stergios I. Roumeliotis. “A Direct Least-Squares (DLS) Method for PnP”.</li> <li><strong>SOLVEPNP_UPNP</strong> Method is based on the paper of A.Penate-Sanchez, J.Andrade-Cetto, F.Moreno-Noguer. “Exhaustive Linearization for Robust Camera Pose and Focal Length Estimation”. In this case the function also estimates the parameters \f$f_x\f$ and \f$f_y\f$ assuming that both have the same value. Then the cameraMatrix is updated with the estimated focal length.</li> </ul> <hr /> <h3 id="1-solvepnp_iterative">1. SOLVEPNP_ITERATIVE</h3> <p>Accroding to <code class="highlighter-rouge">solvepnp.cpp</code>:</p> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>else if (flags == SOLVEPNP_ITERATIVE)
{
    CvMat c_objectPoints = opoints, c_imagePoints = ipoints;
    CvMat c_cameraMatrix = cameraMatrix, c_distCoeffs = distCoeffs;
    CvMat c_rvec = rvec, c_tvec = tvec;
    cvFindExtrinsicCameraParams2(&amp;c_objectPoints, &amp;c_imagePoints, &amp;c_cameraMatrix,
                                 c_distCoeffs.rows*c_distCoeffs.cols ? &amp;c_distCoeffs : 0,
                                 &amp;c_rvec, &amp;c_tvec, useExtrinsicGuess );
    result = true;
}
</code></pre></div></div> <p>Which meanings this Method use the function <code class="highlighter-rouge">cvFindExtrinsicCameraParams2</code> in <code class="highlighter-rouge">calibration.cpp</code>.</p> <h4 id="about-cvfindextrinsiccameraparams2">About cvFindExtrinsicCameraParams2</h4> <p>In this moment, should reference <a href="http://docs.opencv.org/3.1.0/d9/d0c/group__calib3d.html">offical calib3d</a>. In Detailed Desciption, focus on the perspective transformation.</p> <p><img src="http://www.opencv.org.cn/opencvdoc/2.3.2/html/_images/math/50a3464c85a412907d91fd8895108ff692eb8d08.png" alt="original-photo" /></p> <ul> <li>(X, Y, Z) are the coordinates of a 3D point in the world coordinate space</li> <li>(R t) is the Camera’s Rotation and Position, which is what we need to know</li> <li>fx, fy, cx, cy is the Camera’s intrinsic</li> <li>s is Focal length</li> <li>u v are the coordinates of the projection point in pixels(picture)</li> </ul> <p>or can use this table:</p> <p><img src="http://docs.opencv.org/2.4/_images/math/f51a5ba02487486308c29bef720f3186d18abac6.png" alt="other-photo" /></p> <p>In <code class="highlighter-rouge">cvFindExtrinsicCameraParams2</code>, you can get Camera extrinsic from intrinsic, camera intrinsic matrix and distortion coefficients.</p> <p>Camera extrinsic is Camera’s Postion and Rotation, in the other word, if the Camera is static, then can get the Object’s Position and Rotation, but the output is reversed.</p> <h4 id="how-to-calc-cvfindextrinsiccameraparams2">How to Calc cvFindExtrinsicCameraParams2</h4> <p>Back to <code class="highlighter-rouge">cvFindExtrinsicCameraParams2</code>, this function use DLT(Direct Linear Transform) algorithm solve it, and refine extrinsic parameters using Levenberg-Marquardt algorithm.</p> <p><img src="http://rosclub.cn/data/attachment/portal/201612/01/230812wss38nmn2qs08k1f.jpg" alt="DLT" /></p> <p>Then, use Gaussion-Newton minimize the reprojection error.</p> <h3 id="2-solvepnp_p3p">2. SOLVEPNP_P3P</h3> <p>First, we have to know, the P, A, B, C must be Non-coplanar.</p> <p><img src="https://ws1.sinaimg.cn/large/bc1eaf88ly1febvzy7u9sj20m70ez4cc.jpg" alt="P3P_1" /></p> <p>use the law of cosines, we can know:</p> <p><img src="https://latex.codecogs.com/png.latex?%5Cinline%20%5Cbegin%7Balign*%7DY%5E2&plus;Z%5E2-2YZ%5Ccos%5Calpha%3D%7Ba%7D%27%5E2%5C%5CX%5E2&plus;Z%5E2-2XZ%5Ccos%5Cbeta%3D%7Bb%7D%27%5E2%5C%5CX%5E2&plus;Y%5E2-2XY%5Ccos%5Cgamma%3D%7Bc%7D%27%5E2%5C%5C%5Cend%7Balign*%7D" alt="\begin{align*}Y^2+Z^2-2YZ\cos\alpha={a}'^2\X^2+Z^2-2XZ\cos\beta={b}'^2\X^2+Y^2-2XY\cos\gamma={c}'^2\\end{align*}" /></p> <p><img src="https://ws1.sinaimg.cn/large/bc1eaf88ly1febwi6tc88j20m60f4dth.jpg" alt="P3P_2" /></p> <p>Final, Fomulation(13), x can get 4 possible answer. So, use the 4th point to determind the best answer.</p> <p><img src="https://ws1.sinaimg.cn/large/bc1eaf88ly1febwsm7vpjj20m60eh49u.jpg" alt="P3P_3" /></p> <h3 id="3-solvepnp_epnp">3. SOLVEPNP_EPNP</h3> <p>Reference:</p> <ol> <li><a href="http://www.voidcn.com/blog/zhyh1435589631/article/p-6512659.html">关于使用SVD分解方法求解AX=0方程的一点说明</a></li> <li><a href="http://course.shufe.edu.cn/jpkc/jcjx/gdds/exs/ex11.pdf">Document of classbook</a></li> <li><a href="http://rosclub.cn/post-566.html">PnP算法简介与代码解析-柴政</a></li> <li><a href="http://www.cnblogs.com/jian-li/p/5689122.html">SolvePnp Algorithm(Chinese Version)</a> and Paper.</li> </ol> <p>Key Word: SVD(Singular Value Decomposition)</p> <h4 id="31-mx--0">3.1 Mx = 0</h4> <p>First, you should understand that every point can be present by four base point in 3D space. In theory, the control points(four base points) can be chosen arbitrarily, However, in practice, found that the stability of the paper’s method is increased by taking the centroid of the reference points as one, and to select the rest in such a way that they form a basis aligned with the principal directions.</p> <p>First, look at this basic fomulation: P^w meaning points in world coordinate, meanwhile P^c meaning points in camera coordinate. P^c is what we determind first, so every point can be present by four base point.</p> <p><img src="https://latex.codecogs.com/gif.latex?p_i^w=\sum_{j=1}^4\alpha_{ij}c_j^w,&space;\quad&space;with&space;\sum_{j=1}^4\alpha_{ij}=1" alt="p_i^w=\sum_{j=1}^4\alpha_{ij}c_j^w, \quad with \sum_{j=1}^4\alpha_{ij}=1" /></p> <p><img src="https://latex.codecogs.com/gif.latex?p_i^c=\sum_{j=1}^4\alpha_{ij}c_j^c,&space;\quad&space;with&space;\sum_{j=1}^4\alpha_{ij}=1" alt="p_i^c=\sum_{j=1}^4\alpha_{ij}c_j^c, \quad with \sum_{j=1}^4\alpha_{ij}=1 " /></p> <p><img src="http://latex.codecogs.com/gif.latex?\omega_i&space;\begin{bmatrix}&space;U_i&space;\\&space;V_i&space;\\&space;1&space;\end{bmatrix}&space;=&space;\begin{bmatrix}&space;R&space;&amp;&space;T&space;\end{bmatrix}&space;\begin{bmatrix}&space;X&space;\\&space;Y&space;\\&space;Z&space;\\&space;1&space;\end{bmatrix}" alt="\omega_i \begin{bmatrix} U_i \ V_i \ 1 \end{bmatrix} = \begin{bmatrix} R &amp; T \end{bmatrix} \begin{bmatrix} X \ Y \ Z \ 1 \end{bmatrix}" /></p> <p>in this case,</p> <p><img src="http://latex.codecogs.com/gif.latex?\begin{bmatrix}&space;R&space;&amp;&space;T&space;\end{bmatrix}&space;\begin{bmatrix}&space;X&space;\\&space;Y&space;\\&space;Z&space;\\&space;1&space;\end{bmatrix}" alt="\begin{bmatrix} R &amp; T \end{bmatrix} \begin{bmatrix} X \ Y \ Z \ 1 \end{bmatrix}" /></p> <p>is matrix multiplication, Present the object point transform from World coordinate to Camera coordinate, meanings the Object position in Camera view, and this can be present by four base points.</p> <p><img src="https://latex.codecogs.com/gif.latex?\sum_{j=1}^4a_{ij}C^c_j&space;=&space;\begin{bmatrix}&space;R&space;&amp;&space;T&space;\end{bmatrix}&space;\begin{bmatrix}&space;X&space;\\&space;Y&space;\\&space;Z&space;\\&space;1&space;\end{bmatrix}" alt=" \sum_{j=1}^4a_{ij}C^c_j = \begin{bmatrix} R &amp; T \end{bmatrix} \begin{bmatrix} X \ Y \ Z \ 1 \end{bmatrix}" /></p> <p>so,</p> <p><img src="http://latex.codecogs.com/gif.latex?\omega_i&space;\begin{bmatrix}&space;U_i&space;\\&space;V_i&space;\\&space;1&space;\end{bmatrix}&space;=&space;\begin{bmatrix}&space;R&space;&amp;&space;T&space;\end{bmatrix}&space;\begin{bmatrix}&space;X&space;\\&space;Y&space;\\&space;Z&space;\\&space;1&space;\end{bmatrix}&space;=&space;Ap_i^c&space;=&space;A\sum_{j=1}^4a_{ij}C^c_j" alt="\omega_i \begin{bmatrix} U_i \ V_i \ 1 \end{bmatrix} = \begin{bmatrix} R &amp; T \end{bmatrix} \begin{bmatrix} X \ Y \ Z \ 1 \end{bmatrix} = Ap_i^c = A\sum_{j=1}^4a_{ij}C^c_j" /></p> <p>and, from the last row, you can find</p> <p><img src="http://latex.codecogs.com/gif.latex?\omega_i&space;=&space;\sum_{j=1}^4a_{ij}z^c_j" alt="\omega_i = \sum_{j=1}^4a_{ij}z^c_j" /></p> <p>so, this matrix can be,</p> <p><img src="http://latex.codecogs.com/gif.latex?\sum_{j=1}^4\alpha_{ij}f_ux^c_j&plus;\alpha_{ij}(u_c-u_i)z^c_j=0" alt="\sum_{j=1}^4\alpha_{ij}f_ux^c_j+\alpha_{ij}(u_c-u_i)z^c_j=0 " /></p> <p><img src="http://latex.codecogs.com/gif.latex?\sum_{j=1}^4\alpha_{ij}f_v&space;y^c_j&plus;\alpha_{ij}(v_c-v_i)z^c_j=0" alt="\sum_{j=1}^4\alpha_{ij}f_v y^c_j+\alpha_{ij}(v_c-v_i)z^c_j=0" /></p> <p>so, every point have two formulation, so, seems like,</p> <p><img src="http://latex.codecogs.com/gif.latex?[M][X]&space;=&space;0" alt="[M][X] = 0" /></p> <p>[M] is [2n*12] Matrix, [X] is [12*1] (n meanings the number of Object Points, 12-vector unknow is these four basic points’ position in Camera View.)</p> <p>Then, the Question is how to min the Mx. Simple say, The least squares solution is the eigenvector corresponding to the smallest singular value of M ^ TM (最小二乘解就是 M^TM的最小的奇异值所对应的特征向量)。This can get X, meanings C_j^w, base points in Camera coordinate.</p> <p>Because of the noise, we can not just get the x from Mx=0, Although we can calculate the x by Least Squares, which can get answer by M^TMx = M^T0, but we can not only focus the min eigenvector in SVD, we need the 2nd min eigenvector and more .</p> <p>So we need do SVD from A^TA, get the Vj(j is the last 4 column)</p> <p>Reference: <a href="http://www.doc88.com/p-7317011843934.html">SVD-PPT-Chinese</a></p> <h4 id="32-l--betap">3.2 L * beta=P</h4> <p>Focus on X, we know that the solution is smallest singular value, but with the noise, we have to consider penultimate sigular value and others, so consider the follow formulation.</p> <p><img src="https://latex.codecogs.com/gif.latex?X&space;=&space;\sum_{k&space;=&space;1}^N\beta_kV_k" alt="X = \sum_{k = 1}^N\beta_kV_k" /></p> <p>With the paper, we know that the N can be 1,2,3 and 4. When f is small, meanings we choose a small focal length, M^TM have only one zero eigenvalue, however, as the focal length increases and camera becomes closer to being orthograhic, all four smallest eigenvalues approach zero, so the N can be 4. Furthermore, if the correspondences are noisy, the smallest of them will be tiny but not strictly equal to zero.</p> <p>if We do not have noise, we can know the N = 1, and the X is the vector which the eigenvalue is zero. but in natural, the noise and the Object points can not be precise, so we have to make N to be 3 or 4.</p> <p>so we have to solve beta_k. The stratage is whether in World coordinate or Camera coordinate, the length between two points is static, so,</p> <p><img src="https://latex.codecogs.com/gif.latex?\Vert&space;c_i^c&space;-&space;c_j^c\Vert^2=\Vert&space;c_i^w&space;-&space;c_j^w\Vert^2" alt="\Vert c_i^c - c_j^c\Vert^2=\Vert c_i^w - c_j^w\Vert^2" /></p> <p><img src="https://latex.codecogs.com/gif.latex?if&space;N&space;=&space;1,&space;\Vert&space;\beta&space;\rm{v}^{[i]}-\beta&space;\rm{v}^{[j]}\Vert^2=\Vert&space;c_i^w&space;-&space;c_j^w\Vert^2" alt="if N = 1, \Vert \beta \rm{v}^{[i]}-\beta \rm{v}^{[j]}\Vert^2=\Vert c_i^w - c_j^w\Vert^2" /></p> <p>…</p> <p><img src="http://rosclub.cn/data/attachment/portal/201612/01/230806q5fqqfzedkkqqsc5.jpg" alt="EPnP-Solve_beta" /></p> <h4 id="33-gngaussion-newton-iteration">3.3 GN(Gaussion Newton iteration)</h4> <p>Iteration beta, min the cost</p> <p>![Error(\beta )=\sum <em>{(i,j) i &lt; j}(\Vert c_i^c - c_j^c\Vert^2-\Vert c_i^w - c_j^w\Vert^2)](https://latex.codecogs.com/png.latex?%5Cinline%20Error%28%5Cbeta%20%29%3D%5Csum%20</em>%7B%28i%2Cj%29%20i%20%3C%20j%7D%28%5CVert%20c_i%5Ec%20-%20c_j%5Ec%5CVert%5E2-%5CVert%20c_i%5Ew%20-%20c_j%5Ew%5CVert%5E2%29)</p> <p>have to focus on Jacobi iteration.</p> <p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9fc2ba24e56db5f23265cc45aa7243de4d49e86f" alt="Jacobi" /></p> <p>in Newton method:</p> <p><img src="http://latex.codecogs.com/gif.latex?g(x)%7b%5capprox%7dg(%7bx_k%7d)%2bg%27(%7bx_k%7d)(x-%7bx_k%7d)" alt="first" /></p> <p><img src="http://latex.codecogs.com/gif.latex?g(%7bx_k%7d)%2bg%27(%7bx_k%7d)(x-%7bx_k%7d)%3d0" alt="second" /></p> <p><img src="http://latex.codecogs.com/gif.latex?%7bx_%7bk%2b1%7d%7d%3d%7bx_k%7d-%5cfrac%7b1%7d%7b%7bg%27(%7bx_k%7d)%7d%7dg(%7bx_k%7d)" alt="Thrid" /></p> <p>so, in our Error:</p> <p><img src="https://latex.codecogs.com/png.latex?%5Cinline%20%5Cbeta_%7Bk&plus;1%7D%3D%5Cbeta_k-%5Cfrac%7B1%7D%7BJ_f%28%5Cbeta_k%29%7DE%28%5Cbeta_k%29" alt="\beta_{k+1}=\beta_k-\frac{1}{J_f(\beta_k)}E(\beta_k)" /></p> <p>in Picture, this formulation is :</p> <p><img src="https://latex.codecogs.com/png.latex?%5Cinline%20J%28%5Cbeta_0%29%5CDelta%5Cbeta%3D-E%28%5Cbeta_0%29" alt="J(\beta_0)\Delta\beta=-E(\beta_0)" /></p> <p>like this:</p> <p><img src="http://rosclub.cn/data/attachment/portal/201612/01/230808yqzlbl11qlkkcqk5.jpg" alt="Epnp-Gn" /></p> <h4 id="34-recover-3d-points-in-camera-coordinate">3.4 Recover 3d points in camera coordinate</h4> <p>After GN, we can get the best _beta, so we can get the best P^c , with P^w, we can get R and t.</p> <p><img src="https://latex.codecogs.com/gif.latex?X&space;=&space;\sum_{k&space;=&space;1}^N\beta_kV_k" alt="X = \sum_{k = 1}^N\beta_kV_k" /></p> <p>![p_i^c=\sum <em>{j=1}^4\alpha _{ij}c_j^c](https://latex.codecogs.com/png.latex?%5Cinline%20p_i%5Ec%3D%5Csum%20</em>%7Bj%3D1%7D%5E4%5Calpha%20_%7Bij%7Dc_j%5Ec)</p> <h4 id="35-conclusion">3.5 Conclusion</h4> <p>we can use EPnP get the R and t, then use SOLVEPNP_ITERATIVE GN do the last optimize.</p> <p><img src="https://ws1.sinaimg.cn/large/bc1eaf88ly1febnta7r76j20m30ec15p.jpg" alt="" /></p> <h3 id="4-solvepnp_dls">4. SOLVEPNP_DLS</h3> <p>todo</p> <h3 id="5-solvepnp_upnp">5. SOLVEPNP_UPNP</h3> <p>UPnp is similar with EPnP, but UPnP do not know the matrix of intrinsic parameters, eg.(cx,cy) is a principal point that is usually at the image center ,fx,fy are the focal lengths expressed in pixel units.</p> <p>in general, caculate the</p> <p><img src="https://latex.codecogs.com/gif.latex?%5Cinline%20C_j%5Ec%3D%5Cbegin%7Bbmatrix%7DX_j%5Ec%5C%5CY_j%5Ec%5C%5CZ_j%5Ec%5Cend%7Bbmatrix%7D%3D%5Csum_%7Bk%3D1%7D%5EN%5Cbegin%7Bbmatrix%7D%5Cbeta_kV_%7Bk%2Cx%7D%5Ej%5C%5C%5Cbeta_kV_%7Bk%2Cy%7D%5Ej%5C%5Cf%5Cbeta_kV_%7Bk%2Cz%7D%5Ej%5Cend%7Bbmatrix%7D" alt="C_j^c=\begin{bmatrix}X_j^c\Y_j^c\Z_j^c\end{bmatrix}=\sum_{k=1}^N\begin{bmatrix}\beta_kV_{k,x}^j\\beta_kV_{k,y}^j\f\beta_kV_{k,z}^j\end{bmatrix}" /></p> <p>in this case, N can be 1 or 2, sometimes, the with little Object point and too much noise, N have to be 3, but it will take much more time.</p> <p><img src="https://ws1.sinaimg.cn/large/bc1eaf88ly1febzs4ef57j20m60ezdst.jpg" alt="UPnP" /></p> <h2 id="conclusion">Conclusion</h2> <p><img src="https://ws1.sinaimg.cn/large/bc1eaf88ly1fehfx5b2mtj20lq0emjxy.jpg" alt="" /></p> </article> <div class="page-navigation code"> <a class="next" href="https://nimohunter.com/Unity-Java-Protobuf-3.0" title="NEXT: Unity Java Protobuf 3.0">&lt;&lt;</a> <span> &middot; </span> <a class="home" href="https://nimohunter.com/" title="Back to Index">Index</a> <span> &middot; </span> <a class="prev" href="https://nimohunter.com/Install-OpenCV3-QT-in-Debian" title="PREV: Install Opencv3 Qt In Debian">&gt;&gt;</a> </div> </div> <div class="footer"> <span class="block">&copy; 2019 Nimo</span> <span class="block"><small>&lt;/&gt; Powered by <a href="https://jekyllrb.com/">Jekyll</a> and <a href="https://github.com/heiswayi/the-plain">The Plain theme</a>.</small></span> </div> </body> </html>
